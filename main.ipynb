{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-04T08:44:09.028518Z","iopub.status.busy":"2024-10-04T08:44:09.028096Z","iopub.status.idle":"2024-10-04T08:44:09.034394Z","shell.execute_reply":"2024-10-04T08:44:09.033291Z","shell.execute_reply.started":"2024-10-04T08:44:09.028463Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from PIL import Image\n","from torchvision.transforms import v2\n","from torchvision.transforms.v2 import Compose\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.039022Z","iopub.status.busy":"2024-10-04T08:44:09.038709Z","iopub.status.idle":"2024-10-04T08:44:09.052770Z","shell.execute_reply":"2024-10-04T08:44:09.051801Z","shell.execute_reply.started":"2024-10-04T08:44:09.038989Z"},"trusted":true},"outputs":[],"source":["class Compute_Metrics:\n","    def __init__(self):\n","        pass\n","    \n","    def process_output(self, output):\n","        output = torch.argmax(output, dim=-1)\n","        output = output.tolist()\n","        return output\n","        \n","    def compute_accuracy(self, y, y_pred):\n","        accuracy = accuracy_score(y_true=y, y_pred=y_pred)\n","        return accuracy\n","    \n","    def compute_recall(self, y, y_pred):\n","        recall = recall_score(y_true=y, y_pred=y_pred, average='micro')\n","        return recall\n","    \n","    def compute_precision(self, y, y_pred):\n","        precision = precision_score(y_true=y, y_pred=y_pred, average='micro')\n","        return precision\n","    \n","    def compute_f1(self, y, y_pred):\n","        f1 = f1_score(y_true=y, y_pred=y_pred, average='micro')\n","        return f1\n","    \n","    def compute(self, y, y_pred):\n","        y = self.process_output(y)\n","        y_pred = self.process_output(y_pred)\n","        accuracy = self.compute_accuracy(y, y_pred)\n","        precision = self.compute_precision(y, y_pred)\n","        recall = self.compute_recall(y, y_pred)\n","        f1 = self.compute_f1(y, y_pred)\n","        return accuracy, precision, recall, f1"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.055138Z","iopub.status.busy":"2024-10-04T08:44:09.054435Z","iopub.status.idle":"2024-10-04T08:44:09.066646Z","shell.execute_reply":"2024-10-04T08:44:09.065841Z","shell.execute_reply.started":"2024-10-04T08:44:09.055091Z"},"trusted":true},"outputs":[],"source":["class Custom_Dataset(Dataset):\n","    def __init__(self, root_dataset_folder: str, transform: Compose):\n","        super(Custom_Dataset, self).__init__()\n","        self.root_dataset_folder = root_dataset_folder\n","        self.transform = transform\n","        self.images_path = []\n","        self.labels = []\n","        self.name_labels = []\n","        self.load_dataset()\n","\n","    def load_dataset(self):\n","        classes_name = os.listdir(self.root_dataset_folder)\n","        for class_name in classes_name:\n","            self.name_labels.append(class_name)\n","            images_folder = os.path.join(self.root_dataset_folder, class_name)\n","            for dir in os.listdir(images_folder):\n","                image_path = os.path.join(images_folder, dir)\n","                self.images_path.append(image_path)\n","                self.labels.append(classes_name.index(class_name))\n","\n","    def __len__(self):\n","        return len(self.images_path)\n","    \n","    def __getitem__(self, idx):\n","        image_path = self.images_path[idx]\n","        image = Image.open(image_path).convert('L')\n","        x = self.transform(image)\n","        label = self.labels[idx]\n","        y = [0] * len(self.name_labels)\n","        y[label] = 1\n","        y = torch.FloatTensor(y)\n","        return x, y\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.069262Z","iopub.status.busy":"2024-10-04T08:44:09.068459Z","iopub.status.idle":"2024-10-04T08:44:09.082428Z","shell.execute_reply":"2024-10-04T08:44:09.081526Z","shell.execute_reply.started":"2024-10-04T08:44:09.069217Z"},"trusted":true},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, patience=5, delta=0, verbose=False):\n","        self.patience = patience\n","        self.delta = delta\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_metric = float('inf')  # Initialize with positive infinity for loss\n","        self.early_stop = False\n","\n","    def __call__(self, current_metric):\n","        if self.best_metric - current_metric > self.delta:\n","            self.best_metric = current_metric\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","                if self.verbose:\n","                    print(\"Early stopping triggered.\")\n","        return self.early_stop "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.224914Z","iopub.status.busy":"2024-10-04T08:44:09.224612Z","iopub.status.idle":"2024-10-04T08:44:09.256220Z","shell.execute_reply":"2024-10-04T08:44:09.255331Z","shell.execute_reply.started":"2024-10-04T08:44:09.224877Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","class CNN_Block(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, norm='batch_norm', drop_out=0.5):\n","        super(CNN_Block, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.norm = norm\n","        self.drop_out = drop_out\n","        self.cnn = torch.nn.Sequential(\n","            torch.nn.Conv2d(in_channels=self.in_channels, out_channels=self.out_channels, kernel_size=self.kernel_size, stride=self.stride, padding=self.padding)\n","        )        \n","        if norm == 'batch_norm':\n","            self.cnn.append(torch.nn.BatchNorm2d(self.out_channels))\n","        elif norm == 'layer_norm':\n","            self.cnn.append(torch.nn.LayerNorm(self.out_channels))\n","            \n","        if self.drop_out != 0:\n","            self.cnn.append(torch.nn.Dropout(self.drop_out))\n","            \n","    def forward(self, x):\n","        return self.cnn(x)\n","\n","class Residual_Block(torch.nn.Module):\n","    def __init__(self, input_channels, output_channels, drop_out, activate_function='relu'):\n","        super(Residual_Block, self).__init__()\n","        self.input_channels = input_channels\n","        self.output_channels = output_channels\n","        self.drop_out = drop_out\n","        if activate_function == 'relu':\n","            self.activate_function = torch.nn.ReLU()\n","        elif activate_function == 'leaky_relu':\n","            self.activate_function = torch.nn.LeakyReLU()\n","        elif activate_function == 'tanh':\n","            self.activate_function = torch.nn.Tanh()\n","        self.residual = torch.nn.Sequential(\n","            CNN_Block(in_channels=self.input_channels, out_channels=self.output_channels, kernel_size=3, stride=1, padding=1, norm='none', drop_out=0.5),\n","            self.activate_function,\n","            CNN_Block(in_channels=self.output_channels, out_channels=self.output_channels, kernel_size=3, stride=1, padding=1, norm='none', drop_out=0.5)\n","        )\n","        if self.input_channels != self.output_channels:\n","            self.shortcut_connection = CNN_Block(in_channels=self.input_channels, out_channels=self.output_channels, kernel_size=1, stride=1, padding=0, norm='none', drop_out=0.5)\n","        else:\n","            self.shortcut_connection = None\n","\n","    def forward(self, x):\n","        if self.shortcut_connection is not None:\n","            x_shortcut = self.shortcut_connection(x)\n","        else:\n","            x_shortcut = x\n","        output = self.residual(x)\n","        return self.activate_function(output + x_shortcut)\n","    \n","class MLP_Block(torch.nn.Module):\n","    def __init__(self, input_channel, output_channel, activate_function='relu', drop_out=0.5):\n","        super(MLP_Block, self).__init__()\n","        self.input_channel = input_channel\n","        self.output_channel = output_channel\n","        self.activate_function = activate_function\n","        self.drop_out = drop_out\n","        self.mlp = torch.nn.Sequential(torch.nn.Linear(in_features=self.input_channel, out_features=self.output_channel))\n","        if self.activate_function == 'relu':\n","            self.mlp.append(torch.nn.ReLU())\n","        elif self.activate_function == 'leaky_relu':\n","            self.mlp.append(torch.nn.LeakyReLU())\n","        elif self.activate_function == 'tanh':\n","            self.mlp.append(torch.nn.Tanh())\n","        elif self.activate_function == 'softmax':\n","            self.mlp.append(torch.nn.Softmax(dim=-1))\n","        if self.drop_out != 0:\n","            self.mlp.append(torch.nn.Dropout(self.drop_out))\n","    \n","    def forward(self, x):\n","        return self.mlp(x)      \n","    \n","class Resnet34(torch.nn.Module):\n","    def __init__(self, input_channels, output_classes, image_size):\n","        super(Resnet34, self).__init__()\n","        self.input_channels = input_channels\n","        self.output_classes = output_classes\n","        self.image_size = image_size\n","        self.block_1 = torch.nn.Sequential(\n","            CNN_Block(in_channels=self.input_channels, out_channels=16, kernel_size=7, stride=2, padding=3, norm='batch_norm', drop_out=0.5),\n","            torch.nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.block_2 = torch.nn.Sequential(\n","            Residual_Block(input_channels=16, output_channels=16, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=64, output_channels=64, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=64, output_channels=64, drop_out=0.5, activate_function='relu'),\n","        )\n","        self.block_3 = torch.nn.Sequential(\n","            Residual_Block(input_channels=16, output_channels=32, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=128, output_channels=128, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=128, output_channels=128, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=128, output_channels=128, drop_out=0.5, activate_function='relu'),\n","        )\n","        self.block_4 = torch.nn.Sequential(\n","            Residual_Block(input_channels=32, output_channels=64, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=256, output_channels=256, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=256, output_channels=256, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=256, output_channels=256, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=256, output_channels=256, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=256, output_channels=256, drop_out=0.5, activate_function='relu'),\n","        )\n","        self.block_5 = torch.nn.Sequential(\n","            Residual_Block(input_channels=64, output_channels=128, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=512, output_channels=512, drop_out=0.5, activate_function='relu'),\n","#             Residual_Block(input_channels=512, output_channels=512, drop_out=0.5, activate_function='relu'),\n","        )\n","        self.feature_extraction = torch.nn.Sequential(\n","            self.block_1, self.block_2, self.block_3, self.block_4, self.block_5,\n","            torch.nn.AvgPool2d(kernel_size=2),\n","            torch.nn.Flatten(start_dim=1)\n","        )\n","        self.output_size = self.compute_output_dim()\n","        self.mlp = torch.nn.Sequential(\n","            MLP_Block(input_channel=self.output_size, output_channel=1000, activate_function='relu', drop_out=0.5),\n","            MLP_Block(input_channel=1000, output_channel=128, activate_function='relu', drop_out=0.5),\n","            MLP_Block(input_channel=128, output_channel=self.output_classes, activate_function='none', drop_out=0)\n","        )\n","        \n","    def compute_output_dim(self):\n","        x = torch.randn((1, self.input_channels, self.image_size[0], self.image_size[1]))\n","        output = self.feature_extraction(x)\n","        output_size = output.shape\n","        return output_size[-1]\n","    \n","    def forward(self, x):\n","        feature = self.feature_extraction(x)\n","        output = self.mlp(feature)\n","        return output"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.258232Z","iopub.status.busy":"2024-10-04T08:44:09.257861Z","iopub.status.idle":"2024-10-04T08:44:09.295121Z","shell.execute_reply":"2024-10-04T08:44:09.294219Z","shell.execute_reply.started":"2024-10-04T08:44:09.258188Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(self, train_path: str, val_path: str, test_path: str, transform: Compose, \n","                 batch_size: int, optimizer: str, loss_func: str, epochs: int, model: str,\n","                 in_channels: int, input_size: tuple):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.metrics = Compute_Metrics()\n","        # Load Dataset\n","        self.train_path = train_path\n","        self.val_path = val_path\n","        self.test_path = test_path\n","        self.transform = transform\n","        self.train_dataset = Custom_Dataset(self.train_path, self.transform)\n","        self.val_dataset = Custom_Dataset(self.val_path, self.transform)\n","        self.test_dataset = Custom_Dataset(self.val_path, self.transform)\n","        # Create Model\n","        self.in_channels = in_channels\n","        self.num_classes = len(os.listdir(self.train_path))\n","        self.input_size = input_size\n","        if model == 'vgg16':\n","            self.model = VGG16(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        elif model == 'vgg19':\n","            self.model = VGG19(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        elif model == 'resnet18':\n","            self.model = Resnet18(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        elif model == 'resnet34':\n","            self.model = Resnet34(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        elif model == 'resnet50':\n","            self.model = Resnet50(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        elif model == 'vit':\n","             self.model = ViT(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        else:\n","            self.model = VGG16(input_channels=self.in_channels, output_classes=self.num_classes, image_size=self.input_size).to(self.device)\n","        # Create Dataloader\n","        self.batch_size = batch_size\n","        self.train_dataloader = DataLoader(dataset=self.train_dataset, batch_size=self.batch_size, shuffle=True)\n","        self.val_dataloader = DataLoader(dataset=self.val_dataset, batch_size=self.batch_size, shuffle=True)\n","        self.test_dataloader = DataLoader(dataset=self.test_dataset, batch_size=self.batch_size, shuffle=True)\n","        # Training parameters\n","        if optimizer == 'sgd':\n","            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=1e-3)\n","        elif optimizer == 'adamw':\n","            self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=3e-4, weight_decay=1e-3)\n","        else:\n","            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4, weight_decay=1e-3)\n","        if loss_func == 'bce':\n","            self.loss_func = torch.nn.BCELoss()\n","        else:\n","            self.loss_func = torch.nn.CrossEntropyLoss()\n","        self.epochs = epochs\n","        self.early_stop = EarlyStopping(patience=5, delta=1e-3)\n","        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=5)\n","        \n","    def train_func(self):\n","        self.model.train()\n","        loss_value = 0\n","        accuracy_value, precision_value, recall_value, f1_value = 0, 0, 0, 0\n","        for _, (x, y) in enumerate(self.train_dataloader):\n","            x, y = x.to(self.device), y.to(self.device)\n","            y_pred = self.model(x)\n","            loss = self.loss_func(y_pred, y)\n","            self.optimizer.zero_grad()\n","            loss.backward()\n","            self.optimizer.step()\n","            loss_value += loss.item()\n","            accuracy, precision, recall, f1 = self.metrics.compute(y, y_pred)\n","            accuracy_value += accuracy\n","            precision_value += precision\n","            recall_value += recall\n","            f1_value += f1\n","        loss_value = loss_value / len(self.train_dataloader)\n","        accuracy_value = accuracy_value / len(self.train_dataloader)\n","        precision_value = precision_value / len(self.train_dataloader)\n","        recall_value = recall_value / len(self.train_dataloader)\n","        f1_value = f1_value / len(self.train_dataloader)\n","        return loss_value, accuracy_value, precision_value, recall_value, f1_value\n","    \n","    def val_func(self):\n","        self.model.eval()\n","        with torch.no_grad():\n","            loss_value = 0\n","            accuracy_value, precision_value, recall_value, f1_value = 0, 0, 0, 0\n","            for _, (x, y) in enumerate(self.val_dataloader):\n","                x, y = x.to(self.device), y.to(self.device)\n","                y_pred = self.model(x)\n","                loss = self.loss_func(y_pred, y)\n","                loss_value += loss.item()\n","                accuracy, precision, recall, f1 = self.metrics.compute(y, y_pred)\n","                accuracy_value += accuracy\n","                precision_value += precision\n","                recall_value += recall\n","                f1_value += f1\n","            loss_value = loss_value / len(self.val_dataloader)\n","            accuracy_value = accuracy_value / len(self.val_dataloader)\n","            precision_value = precision_value / len(self.val_dataloader)\n","            recall_value = recall_value / len(self.val_dataloader)\n","            f1_value = f1_value / len(self.val_dataloader)\n","            return loss_value, accuracy_value, precision_value, recall_value, f1_value\n","    \n","    def test_func(self):\n","        self.model.eval()\n","        loss_value = 0\n","        for _, (x, y) in enumerate(self.test_dataloader):\n","            x, y = x.to(self.device), y.to(self.device)\n","            y_pred = self.model(x)\n","            loss = self.loss_func(y_pred, y)\n","            loss_value += loss.item()\n","        loss_value = loss_value / len(self.test_dataloader)\n","        return loss_value\n","        \n","    def train(self):\n","        for epoch in range(self.epochs):\n","            train_loss, train_accuracy_value, train_precision_value, train_recall_value, train_f1_value = self.train_func()\n","            val_loss, val_accuracy_value, val_precision_value, val_recall_value, val_f1_value = self.val_func()\n","            print(f\"Epoch: {epoch:2d} - Train loss: {train_loss:.2f} - Val loss: {val_loss:.2f} - Train accuracy {train_accuracy_value:.2f} - Val accuracy {val_accuracy_value:.2f} - Train precision {train_precision_value:.2f} - Val precision {val_precision_value:.2f} - Train recall: {train_recall_value:.2f} - Val recall: {val_recall_value:.2f} - Train f1: {train_f1_value:.2f} - Val f1: {val_f1_value:.2f}\")\n","            self.lr_scheduler.step(val_loss)\n","            if self.early_stop(val_loss):\n","                print(\"Early Stopping!!!\")\n","                break\n","                \n","    def inference(self, image: Image):\n","        self.model.eval()\n","        with torch.no_grad():\n","            x = self.transform(image)\n","            x = torch.unsqueeze(x, 0)\n","            y_pred = self.model(x)\n","            idx = torch.argmax(y_pred, dim=-1)\n","            return idx\n","        \n","    def save_model(self, save_path):\n","        torch.save(self.model.state_dict(), save_path)\n","\n","    def load_model(self, save_path):\n","        self.model.load_state_dict(torch.load(save_path, map_location=self.device, weights_only=True))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.297074Z","iopub.status.busy":"2024-10-04T08:44:09.296334Z","iopub.status.idle":"2024-10-04T08:44:09.782449Z","shell.execute_reply":"2024-10-04T08:44:09.781602Z","shell.execute_reply.started":"2024-10-04T08:44:09.297032Z"},"trusted":true},"outputs":[],"source":["train_path = 'dataset/Flower_Recognition_augment/train'\n","val_path = 'dataset/Flower_Recognition_augment/val'\n","test_path = 'dataset/Flower_Recognition_augment/test'\n","batch_size = 64\n","optimizer = 'adam'\n","loss_func = 'cross_entropy'\n","epochs = 50\n","model = 'resnet34'\n","in_channels = 1\n","input_size = (160, 160)\n","save_path = 'flower.pt'\n","transform = v2.Compose([\n","    v2.Resize(input_size, antialias=True),\n","    v2.PILToTensor(),\n","    v2.ToDtype(torch.float)\n","])\n","trainer = Trainer(train_path=train_path, val_path=val_path, test_path=test_path, transform=transform, \n","                 batch_size=batch_size, optimizer=optimizer, loss_func=loss_func, epochs=epochs, model=model,\n","                 in_channels=in_channels, input_size=input_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.train()\n","trainer.save_model(save_path)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:44:09.785034Z","iopub.status.busy":"2024-10-04T08:44:09.784694Z","iopub.status.idle":"2024-10-04T08:50:21.065579Z","shell.execute_reply":"2024-10-04T08:50:21.064431Z","shell.execute_reply.started":"2024-10-04T08:44:09.784999Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch:  0 - Train loss: 1.55 - Val loss: 1.57 - Train accuracy 0.29 - Val accuracy 0.33 - Train precision 0.29 - Val precision 0.33 - Train recall: 0.29 - Val recall: 0.33 - Train f1: 0.29 - Val f1: 0.33\n","Epoch:  1 - Train loss: 1.45 - Val loss: 1.55 - Train accuracy 0.39 - Val accuracy 0.34 - Train precision 0.39 - Val precision 0.34 - Train recall: 0.39 - Val recall: 0.34 - Train f1: 0.39 - Val f1: 0.34\n","Epoch:  2 - Train loss: 1.37 - Val loss: 1.54 - Train accuracy 0.45 - Val accuracy 0.38 - Train precision 0.45 - Val precision 0.38 - Train recall: 0.45 - Val recall: 0.38 - Train f1: 0.45 - Val f1: 0.38\n","Epoch:  3 - Train loss: 1.29 - Val loss: 1.49 - Train accuracy 0.49 - Val accuracy 0.36 - Train precision 0.49 - Val precision 0.36 - Train recall: 0.49 - Val recall: 0.36 - Train f1: 0.49 - Val f1: 0.36\n","Epoch:  4 - Train loss: 1.21 - Val loss: 1.43 - Train accuracy 0.52 - Val accuracy 0.40 - Train precision 0.52 - Val precision 0.40 - Train recall: 0.52 - Val recall: 0.40 - Train f1: 0.52 - Val f1: 0.40\n","Epoch:  5 - Train loss: 1.15 - Val loss: 1.41 - Train accuracy 0.55 - Val accuracy 0.42 - Train precision 0.55 - Val precision 0.42 - Train recall: 0.55 - Val recall: 0.42 - Train f1: 0.55 - Val f1: 0.42\n","Epoch:  6 - Train loss: 1.08 - Val loss: 1.48 - Train accuracy 0.59 - Val accuracy 0.42 - Train precision 0.59 - Val precision 0.42 - Train recall: 0.59 - Val recall: 0.42 - Train f1: 0.59 - Val f1: 0.42\n","Epoch:  7 - Train loss: 1.01 - Val loss: 1.51 - Train accuracy 0.62 - Val accuracy 0.43 - Train precision 0.62 - Val precision 0.43 - Train recall: 0.62 - Val recall: 0.43 - Train f1: 0.62 - Val f1: 0.43\n","Epoch:  8 - Train loss: 0.93 - Val loss: 1.29 - Train accuracy 0.65 - Val accuracy 0.49 - Train precision 0.65 - Val precision 0.49 - Train recall: 0.65 - Val recall: 0.49 - Train f1: 0.65 - Val f1: 0.49\n","Epoch:  9 - Train loss: 0.83 - Val loss: 1.43 - Train accuracy 0.69 - Val accuracy 0.47 - Train precision 0.69 - Val precision 0.47 - Train recall: 0.69 - Val recall: 0.47 - Train f1: 0.69 - Val f1: 0.47\n","Epoch: 10 - Train loss: 0.76 - Val loss: 1.45 - Train accuracy 0.73 - Val accuracy 0.47 - Train precision 0.73 - Val precision 0.47 - Train recall: 0.73 - Val recall: 0.47 - Train f1: 0.73 - Val f1: 0.47\n","Epoch: 11 - Train loss: 0.68 - Val loss: 1.44 - Train accuracy 0.76 - Val accuracy 0.48 - Train precision 0.76 - Val precision 0.48 - Train recall: 0.76 - Val recall: 0.48 - Train f1: 0.76 - Val f1: 0.48\n","Epoch: 12 - Train loss: 0.60 - Val loss: 1.69 - Train accuracy 0.79 - Val accuracy 0.48 - Train precision 0.79 - Val precision 0.48 - Train recall: 0.79 - Val recall: 0.48 - Train f1: 0.79 - Val f1: 0.48\n","Epoch: 13 - Train loss: 0.54 - Val loss: 1.38 - Train accuracy 0.81 - Val accuracy 0.49 - Train precision 0.81 - Val precision 0.49 - Train recall: 0.81 - Val recall: 0.49 - Train f1: 0.81 - Val f1: 0.49\n","Early Stopping!!!\n"]}],"source":["trainer.train()\n","trainer.save_model(save_path)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T08:50:21.067571Z","iopub.status.busy":"2024-10-04T08:50:21.067124Z","iopub.status.idle":"2024-10-04T08:50:21.080569Z","shell.execute_reply":"2024-10-04T08:50:21.079544Z","shell.execute_reply.started":"2024-10-04T08:50:21.067522Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":8782,"sourceId":2431805,"sourceType":"datasetVersion"},{"datasetId":5727835,"sourceId":9428603,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":".myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
